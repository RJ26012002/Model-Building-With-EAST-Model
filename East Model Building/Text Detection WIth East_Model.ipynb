{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd18eae-13af-41c7-9f15-758f1c5b24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Replace 'file.npy' with your .npy file path\n",
    "# # array = np.load('C:/Users/virtu/Downloads/Data/X.npy')\n",
    "# array = np.load('ans.npy')\n",
    "# print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e713abb3-970c-4aa0-9a5a-f0c5a3937f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading the necessary packages \n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438bf224-3e34-4e75-bfb3-16b6b760359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating argument dictionary for the default arguments needed in the code. \n",
    "args = {\"image\":\"Template5_Instance0.jpg\", \"east\":\"D:/EAST_Model/frozen_east_text_detection.pb\", \"min_confidence\":0.5, \"width\":320, \"height\":320}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808a49a3-1aa3-4e45-94c5-fb0bad4a4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "args['image']=\"Template5_Instance0.jpg\"\n",
    "image = cv2.imread(args['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529e0d8a-74b3-4d1e-9912-4059f55ed71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a original image and shape\n",
    "orig = image.copy()\n",
    "(origH, origW) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b56ce77-88ec-4ce1-be73-1afea4922f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the new height and width to default 320 by using args #dictionary.  \n",
    "(newW, newH) = (args[\"width\"], args[\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956a8b97-3fcf-4223-8528-e261c8f50112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the ratio between original and new image for both height and weight. \n",
    "#This ratio will be used to translate bounding box location on the original image. \n",
    "rW = origW / float(newW)\n",
    "rH = origH / float(newH)\n",
    "\n",
    "# resize the original image to new dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7269534-09e7-42fe-bc72-4374b4013dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a blob from the image to forward pass it to EAST model\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc0f1f0-7d66-4097-bd3d-4c3288f6380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained EAST model for text detection \n",
    "net = cv2.dnn.readNet(args[\"east\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19d4b55-51aa-40db-af89-d57ab9df794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to get two outputs from the EAST model. \n",
    "#1. Probabilty scores for the region whether that contains text or not. \n",
    "#2. Geometry of the text -- Coordinates of the bounding box detecting a text\n",
    "# The following two layer need to pulled from EAST model for achieving this. \n",
    "layerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991bb5d4-e98e-4d6b-8141-c67f4a40a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass the blob from the image to get the desired output layers\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c5bbb8-b812-4ae0-92e9-6a6184c244f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns a bounding box and probability score if it is more than minimum confidence\n",
    "def predictions(prob_score, geo):\n",
    "\t(numR, numC) = prob_score.shape[2:4]\n",
    "\tboxes = []\n",
    "\tconfidence_val = []\n",
    "\n",
    "\t# loop over rows\n",
    "\tfor y in range(0, numR):\n",
    "\t\tscoresData = prob_score[0, 0, y]\n",
    "\t\tx0 = geo[0, 0, y]\n",
    "\t\tx1 = geo[0, 1, y]\n",
    "\t\tx2 = geo[0, 2, y]\n",
    "\t\tx3 = geo[0, 3, y]\n",
    "\t\tanglesData = geo[0, 4, y]\n",
    "\n",
    "\t\t# loop over the number of columns\n",
    "\t\tfor i in range(0, numC):\n",
    "\t\t\tif scoresData[i] < args[\"min_confidence\"]:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t(offX, offY) = (i * 4.0, y * 4.0)\n",
    "\n",
    "\t\t\t# extracting the rotation angle for the prediction and computing the sine and cosine\n",
    "\t\t\tangle = anglesData[i]\n",
    "\t\t\tcos = np.cos(angle)\n",
    "\t\t\tsin = np.sin(angle)\n",
    "\n",
    "\t\t\t# using the geo volume to get the dimensions of the bounding box\n",
    "\t\t\th = x0[i] + x2[i]\n",
    "\t\t\tw = x1[i] + x3[i]\n",
    "\n",
    "\t\t\t# compute start and end for the text pred bbox\n",
    "\t\t\tendX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n",
    "\t\t\tendY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n",
    "\t\t\tstartX = int(endX - w)\n",
    "\t\t\tstartY = int(endY - h)\n",
    "\n",
    "\t\t\tboxes.append((startX, startY, endX, endY))\n",
    "\t\t\tconfidence_val.append(scoresData[i])\n",
    "\n",
    "\t# return bounding boxes and associated confidence_val\n",
    "\treturn (boxes, confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c99a5e-da7e-4ed0-8c9e-d3f72776f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find predictions and  apply non-maxima suppression\n",
    "(boxes, confidence_val) = predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(boxes), probs=confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ceabbc1-c71e-480d-852d-526ae1eb512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Text Detection and Recognition \n",
    "\n",
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes to find the coordinate of bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "\t# scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n",
    "\tstartX = int(startX * rW)\n",
    "\tstartY = int(startY * rH)\n",
    "\tendX = int(endX * rW)\n",
    "\tendY = int(endY * rH)\n",
    "\n",
    "\t#extract the region of interest\n",
    "\tr = orig[startY:endY, startX:endX]\n",
    "\n",
    "\t#configuration setting to convert image to string.  \n",
    "\tconfiguration = (\"-l eng --oem 1 --psm 8\")\n",
    "    ##This will recognize the text from the image of bounding box\n",
    "\ttext = pytesseract.image_to_string(r, config=configuration)\n",
    "\n",
    "\t# append bbox coordinate and associated text to the list of results \n",
    "\tresults.append(((startX, startY, endX, endY), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030ba2d-b7b9-4816-8558-18579dd44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaress:259\n",
      "\n",
      "\n",
      "oeâ€™\n",
      "\n",
      "\n",
      "iii\n",
      "\n",
      "\n",
      "ee\n",
      "\n",
      "\n",
      "Thank you for your\n",
      "\n",
      "\n",
      "onus\n",
      "\n",
      "\n",
      "id seventy-\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the image with bounding box and recognized text\n",
    "orig_image = orig.copy()\n",
    "\n",
    "# Moving over the results and display on the image\n",
    "for ((start_X, start_Y, end_X, end_Y), text) in results:\n",
    "\t# display the text detected by Tesseract\n",
    "\tprint(\"{}\\n\".format(text))\n",
    "\n",
    "\t# Displaying text\n",
    "\ttext = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n",
    "\tcv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n",
    "\t\t(0, 0, 255), 2)\n",
    "\tcv2.putText(orig_image, text, (start_X, start_Y - 30),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0, 255), 2)\n",
    "\n",
    "plt.imshow(orig_image)\n",
    "plt.title('Output')\n",
    "# plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7792dc2b-ff9d-4482-9183-803456517337",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f29156-05f6-4e41-9597-6639dcabca5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
